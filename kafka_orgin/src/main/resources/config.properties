####################################################  公共参数  ####################################################
bootstrap.servers=xxxxx
topic=mytopic
zookeeper=xxx:2181

####################################################  生产者参数  ####################################################
#ack字符串类型:1 leader成功 0不等待返回 -1或者all isr中副本全部写入(默认1)
producer.acks=1
#client标识
producer.client.id=producer_client_id
#生产者重试(默认0)
producer.retries=0
#生产者重试之间的间隔时间(默认100)
producer.retry.backoff.ms=100
#消息发送成功之前可以发送多少批次消息(默认5)
producer.max.in.flight.requests.per.connection=5
#消息缓冲区大小,(默认32M)
producer.buffer.memory=33554432
#发送缓冲区中的每个ProducerBatch的大小,如果消息大于这个值会更改这个batch的大小(默认16K)
producer.batch.size=16384
#ProducerBatch如果没有满等待多久发送,增大可提高吞吐(默认0)
producer.linger.ms=0
#发送速度小于消息产生速度,发送缓冲区满了,最大的阻塞时间超过报异常(默认60000)
producer.max.block.ms=60000
#生产者分区器(默认org.apache.kafka.clients.producer.internals.DefaultPartitioner)
producer.partitioner=org.apache.kafka.clients.producer.internals.DefaultPartitioner
#生产者拦截器默认(无)
producer.interceptor=com.anji.kakfa.producer.config.interceptor.MyProducerInterceptor
#生产者key序列化器
producer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
#生产者value序列化器
producer.value.serializer=org.apache.kafka.common.serialization.StringSerializer
#生产者一次最大发送消息的大小,如果一条消息的大小超过就报异常(默认1M)
producer.max.request.size=1048576
#压缩类型,none,gzip,snappy,lz4(默认none),以时间换空间
producer.compression.type=none
#多久关闭闲置连接(默认540000)
producer.connections.max.idle.ms=540000
#socket接收缓冲区大小-1为系统默认(默认大小32k)
producer.receive.buffer.bytes=32768
#socket发送缓冲区大小-1为系统默认(默认大小128k)
producer.send.buffer.bytes=131072
#producer等待多久没有响应便重新发送要设置比broker端参数replica.lag.time.max.ms大(默认30s)
#replica.lag.time.max.ms=10000副本多久未拉取leader数据被踢出isr
producer.request.timeout.ms=30000
#是否开启幂等性(默认false)
producer.enable.idempotence=false
#没有broker变化和分区变化时刷新元数据的间隔时间
producer.metadata.max.age.ms=300000

####################################################  消费者参数  ####################################################
#消费者组id
consumer.group.id=mygroup4
#消费者client id
consumer.client.id=consumer_client_id
#从哪里开始消费数据latest,earliest, none(默认latest)
consumer.auto.offset.reset=earliest
#自动提交偏移量
consumer.enable.auto.commit=true
#自动提交偏移量时间间隔(默认5秒)
consumer.auto.commit.interval.ms=5000
#消费者者拦截器默认(无)
consumer.interceptor=com.anji.kakfa.consumer.config.interceptor.MyConsumerInterceptor
#消费者key反序列化器
consumer.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#消费者value反序列化器
consumer.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#消费者分区分配策略 RoundRobinAssignor StickyAssignor 默认(RangeAssignor)
consumer.partition.assignment.strategy=org.apache.kafka.clients.consumer.RangeAssignor
#调用poll时,kafka端如果能发送给消费者的数据小于这个值就等待发送(默认1B)
consumer.fetch.min.bytes=1
#poll时从kafka最大拉取的数据大小(默认50M),如果单一条消息大于这个值,每次只能接受一条消息
consumer.fetch.max.bytes=52428800
#没有满足最小消息大小时,等待返回时间(默认500ms)
consumer.fetch.max.wait.ms=500
#一次最多从一个分区拉取多少数据(默认1M)
consumer.max.partition.fetch.bytes=1048576
#最大一次poll的数据条数(默认500条)
consumer.max.poll.records=500
#多久关闭空置连接(默认9分钟)
consumer.connections.max.idle.ms=540000
#通过正则订阅不到内部的topic,只能subscribe(内部主题名)来订阅(默认true)
consumer.exclude.internal.topics=true
#socket接收消息缓冲区大小(默认64k)
consumer.receive.buffer.bytes=65536
#socket发送消息缓冲区大小(默认128k)
consumer.send.buffer.bytes=131072
#consumer等待响应的最大等待时间(默认30秒)
consumer.request.timeout.ms=30000
#没有broker变化和分区变化时刷新元数据的间隔时间
consumer.metadata.max.age.ms=300000
#防止消费者一直向broker发送请求的间隔默认(50毫秒)
consumer.reconnect.backoff.ms=50
#配置重新发送失败请求到指定主题之间的间隔(默认100ms)
consumer.retry.backoff.ms=100
#事务隔离级别,read_committed,可以消费LSO的数据(默认read_uncommitted即可以消费HW数据)
consumer.isolation.level=read_uncommitted
#分组管理到消费者协调器的预计时间,必须小于consumer.hearbeat.interval.ms的三分之一
consumer.heartbeat.interval.ms=3000
#组管理协议检测消费者失效时间默认(10秒)
consumer.session.timeout.ms=10000
#如果超过30秒没有poll,则认为consumer离开,触发再均衡(默认30秒)
consumer.max.poll.interval.ms=300000

####################################################  主题参数  ####################################################
#主题一条消息的最大大小默认(1000012).message.max.bytes=1000012 服务端最大接受的消息指批次
topic.max.message.bytes=1000012 
#过期日志的删除策略,compact(默认delete)
topic.cleanup.policy=delete
#消息压缩格式,uncompressed,snappy,lz4,gzip默认(producer保留消费者提供的)
topic.compression.type=producer
#被标识删除的数据能保留多久默认(1天)
topic.delete.retention.ms=86400000
